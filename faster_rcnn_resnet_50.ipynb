{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster RCNN\n",
    "\n",
    "We will be looking into the Faster RCNN Model available in Torch. This model is trained in the MS COCO dataset (which is a common public access database with over 80 classes). In this notebook we will use the model with our data and we are going to just exctract all the cases of a pedestrian which the model detects.\n",
    "\n",
    "We are going to use OpenCV and Numpy to process our images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os import path\n",
    "import numpy as np\n",
    "from torch import device\n",
    "from torch import cuda\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the image and annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = path.join\n",
    "\n",
    "# image path and annotations path.\n",
    "img_path, ann_path = 'PRW/frames', 'PRW/annotations'\n",
    "\n",
    "# get the image names.\n",
    "img_names = sorted(list(listdir(img_path)))\n",
    "img_names = [join(img_path, name) for name in img_names]\n",
    "\n",
    "# get the annoation names.\n",
    "ann_names = sorted(list(listdir(ann_path)))\n",
    "ann_names = [join(ann_path, name) for name in ann_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# define the torchvision image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def predict(image, model, device, detection_threshold):\n",
    "\n",
    "    # transform the image to tensor\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0) # add a batch dimension\n",
    "    outputs = model(image)     # get the predictions on the image\n",
    "\n",
    "    # get all the predicited class names\n",
    "    pred_labels = outputs[0]['labels'].cpu().numpy()\n",
    "\n",
    "    # get score for all the predicted objects\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "    # get all the predicted bounding boxes\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "\n",
    "    # get boxes above the threshold score\n",
    "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
    "    labels = pred_labels[pred_scores >= detection_threshold]\n",
    "\n",
    "\n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, labels, image):\n",
    "\n",
    "    # create a color for the bounding box.\n",
    "    COLOR = [255, 0, 0] \n",
    "  \n",
    "    # read the image with OpenCV\n",
    "    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # draw only the boxes which are persons.\n",
    "    for i, box in enumerate(boxes):\n",
    "        if labels[i] == 1:\n",
    "            cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), COLOR, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model.\n",
    "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "model = fasterrcnn_resnet50_fpn(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device.\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction.\n",
    "image = Image.open(img_names[0])\n",
    "model.eval().to(device)\n",
    "boxes, labels = predict(image, model, device, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = draw_boxes(boxes, labels, image)\n",
    "\n",
    "# display the image.\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Image')\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
