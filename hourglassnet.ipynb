{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## HourGlass Network.\n",
    "\n",
    "Creating a smaller version of the hourglass network (encoding/decoding network). The hourglass network is usually used in a stacked fashion. In the CenterNet Model (which is a Object Detection Algorithm/Architecture), they use a stacked hourglass network for feature extraction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from scipy.io import loadmat\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:39.138304Z",
     "end_time": "2023-04-16T19:13:41.070843Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The BottleNeck block is a Residual Module, which is used to"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"Creates a ResNet Block for feature extraction.\"\"\"\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim):\n",
    "        \"\"\"Instantiates the Residual Module.\"\"\"\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        # half the output dimension.\n",
    "        out = out_dim//2\n",
    "\n",
    "        # sequence of layers (Batch Normalization, ReLu, Convolution)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(inp_dim)\n",
    "        self.conv1 = nn.Conv2d(inp_dim, out, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out)\n",
    "        self.conv2 = nn.Conv2d(out, out, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(out)\n",
    "        self.conv3 = nn.Conv2d(out, out_dim, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        # add a skip layer for residual information\n",
    "        self.skip_layer = nn.Conv2d(inp_dim, out_dim, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.need_skip = not (inp_dim == out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines a forward pass of the ResNet block.\"\"\"\n",
    "\n",
    "        # save residual information.\n",
    "        residual = self.skip_layer(x) if self.need_skip else x\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out += residual\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.076681Z",
     "end_time": "2023-04-16T19:13:41.079095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Hourglass(nn.Module):\n",
    "    \"\"\"Hourglass Module.\"\"\"\n",
    "\n",
    "    def __init__(self, n, filters, bn=None):\n",
    "        \"\"\"Creates an Hourglass Module/Network.\"\"\"\n",
    "\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.n = n\n",
    "        # up-sampling data.\n",
    "        self.up1 = ResNetBlock(filters, filters)\n",
    "        # encoding/feature extraction.\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.low1 = ResNetBlock(filters, filters)\n",
    "        # recursion to add more resnet blocks.\n",
    "        self.low2 = Hourglass(n-1, filters, bn=bn) if self.n > 1 else ResNetBlock(filters, filters)\n",
    "        self.low3 = ResNetBlock(filters, filters)\n",
    "        # up-sampling data.\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the Hourglass Module.\"\"\"\n",
    "\n",
    "        up1  = self.up1(x)\n",
    "        pool1 = self.pool1(x)\n",
    "        # encoding (lower levels).\n",
    "        low1 = self.low1(pool1)\n",
    "        low2 = self.low2(low1)\n",
    "        low3 = self.low3(low2)\n",
    "        up2  = self.up2(low3)\n",
    "\n",
    "        # decoding (up-sampling).\n",
    "        return up1 + up2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.082646Z",
     "end_time": "2023-04-16T19:13:41.085030Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class HourGlassNetwork(nn.Module):\n",
    "    \"\"\"Creates an Hourglass Network.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape=(256, 256, 3), num_stack=1, num_residual=1, num_heatmap=1):\n",
    "        \"\"\"Instantiates the network (we want single center key points.)\"\"\"\n",
    "\n",
    "        super(HourGlassNetwork, self).__init__()\n",
    "\n",
    "        # initial feature extraction layers.\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.res1 = ResNetBlock(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.res2 = ResNetBlock(128, 128)\n",
    "        self.res3 = ResNetBlock(128, 256)\n",
    "        self.hg1 = Hourglass(4, 256)\n",
    "        self.linear = nn.Conv2d(256, 256, kernel_size=1, padding=0, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.y = nn.Conv2d(256, num_heatmap, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.res3(out)\n",
    "        out = self.hg1(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.y(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.091351Z",
     "end_time": "2023-04-16T19:13:41.100004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "HourGlassNetwork(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU()\n  (res1): ResNetBlock(\n    (relu): ReLU()\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    (skip_layer): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (res2): ResNetBlock(\n    (relu): ReLU()\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    (skip_layer): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (res3): ResNetBlock(\n    (relu): ReLU()\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n    (skip_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (hg1): Hourglass(\n    (up1): ResNetBlock(\n      (relu): ReLU()\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n      (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (low1): ResNetBlock(\n      (relu): ReLU()\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n      (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (low2): Hourglass(\n      (up1): ResNetBlock(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (low1): ResNetBlock(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (low2): Hourglass(\n        (up1): ResNetBlock(\n          (relu): ReLU()\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n          (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (low1): ResNetBlock(\n          (relu): ReLU()\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n          (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (low2): Hourglass(\n          (up1): ResNetBlock(\n            (relu): ReLU()\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          (low1): ResNetBlock(\n            (relu): ReLU()\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (low2): ResNetBlock(\n            (relu): ReLU()\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (low3): ResNetBlock(\n            (relu): ReLU()\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (up2): Upsample(scale_factor=2.0, mode='nearest')\n        )\n        (low3): ResNetBlock(\n          (relu): ReLU()\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n          (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (up2): Upsample(scale_factor=2.0, mode='nearest')\n      )\n      (low3): ResNetBlock(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (up2): Upsample(scale_factor=2.0, mode='nearest')\n    )\n    (low3): ResNetBlock(\n      (relu): ReLU()\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n      (skip_layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (up2): Upsample(scale_factor=2.0, mode='nearest')\n  )\n  (linear): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (y): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "DEVICE = torch.device('mps' if torch.has_mps else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create the model.\n",
    "model = HourGlassNetwork()\n",
    "model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.094530Z",
     "end_time": "2023-04-16T19:13:41.262135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.260029Z",
     "end_time": "2023-04-16T19:13:41.269608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "img_path = r'/Users/chiahaohsutai/Documents/GitHub/PRW/frames/c1s1_000801.jpg'\n",
    "image = cv.imread(img_path)\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "image = cv.resize(image, (256, 256))\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "process = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "img = process(image).unsqueeze(0).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.265149Z",
     "end_time": "2023-04-16T19:13:41.321579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 256, 256])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.294473Z",
     "end_time": "2023-04-16T19:13:41.330499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.298873Z",
     "end_time": "2023-04-16T19:13:41.831350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 64, 64])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.831663Z",
     "end_time": "2023-04-16T19:13:41.834846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-0.7719, -0.7055, -0.6553,  ..., -0.3752, -0.3756, -0.3780],\n          [-0.7516, -0.6886, -0.6303,  ..., -0.3754, -0.3848, -0.3780],\n          [-0.7233, -0.6466, -0.5703,  ..., -0.3787, -0.4078, -0.4102],\n          ...,\n          [-0.2260, -0.2165, -0.2095,  ..., -0.2683, -0.2704, -0.2730],\n          [-0.2055, -0.2107, -0.2116,  ..., -0.2524, -0.2474, -0.2523],\n          [-0.2095, -0.2072, -0.2014,  ..., -0.2529, -0.2542, -0.2572]]]],\n       device='mps:0')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:41.835987Z",
     "end_time": "2023-04-16T19:13:42.051022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 64, 64])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.051867Z",
     "end_time": "2023-04-16T19:13:42.055120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 2.2318,  2.2489,  2.2489,  ...,  0.1426,  0.3652,  0.1597],\n          [ 2.2318,  2.2489,  2.2489,  ...,  0.1768,  0.2282,  0.0912],\n          [ 2.2489,  2.2489,  2.2489,  ...,  0.1426,  0.2453,  0.1597],\n          ...,\n          [ 0.1597,  0.1254,  0.1768,  ..., -0.5424, -0.4911, -0.6109],\n          [ 0.1597,  0.0741,  0.0741,  ..., -0.6109, -0.6109, -0.5253],\n          [ 0.0912, -0.0287, -0.0629,  ..., -0.6109, -0.6109, -0.5424]],\n\n         [[ 2.4111,  2.4286,  2.4286,  ...,  0.2752,  0.4153,  0.2927],\n          [ 2.4111,  2.4286,  2.4286,  ...,  0.3102,  0.2927,  0.2227],\n          [ 2.4286,  2.4286,  2.4286,  ...,  0.2752,  0.3102,  0.2927],\n          ...,\n          [ 0.2227,  0.1877,  0.2577,  ..., -0.4951, -0.4076, -0.5476],\n          [ 0.2577,  0.1702,  0.2052,  ..., -0.5126, -0.4951, -0.4601],\n          [ 0.1877,  0.0651,  0.0651,  ..., -0.5126, -0.4951, -0.4951]],\n\n         [[ 2.6226,  2.6400,  2.6400,  ...,  0.4962,  0.6531,  0.5136],\n          [ 2.6226,  2.6400,  2.6400,  ...,  0.5311,  0.5311,  0.4439],\n          [ 2.6400,  2.6400,  2.6400,  ...,  0.4962,  0.5311,  0.5136],\n          ...,\n          [ 0.4614,  0.4265,  0.4962,  ..., -0.2881, -0.1661, -0.2881],\n          [ 0.4962,  0.4091,  0.4265,  ..., -0.2707, -0.2707, -0.2358],\n          [ 0.4265,  0.2871,  0.2871,  ..., -0.2881, -0.2707, -0.2532]]]],\n       device='mps:0')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.055483Z",
     "end_time": "2023-04-16T19:13:42.166965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ann_path = r'/Users/chiahaohsutai/Documents/GitHub/PRW/annotations/c1s1_000801.jpg.mat'\n",
    "annotation = loadmat(ann_path)['box_new']\n",
    "annotation = [ann[1:] for ann in annotation]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.168059Z",
     "end_time": "2023-04-16T19:13:42.172116Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1460.84557235,  405.20842333,  151.61987041,  387.21382289]),\n array([1018.75053996,  419.20410367,   60.64794816,  177.27861771]),\n array([191.90388769, 468.18898488,  55.98272138, 139.95680346]),\n array([853.1349892 , 442.53023758,  48.98488121, 121.29589633])]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.173544Z",
     "end_time": "2023-04-16T19:13:42.176642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "centers = []\n",
    "for ann in annotation:\n",
    "    x, y, w, h = ann\n",
    "    centers.append((x+(w/2), y+(h/2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.177715Z",
     "end_time": "2023-04-16T19:13:42.183618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1536.6555075593953, 598.8153347732183),\n (1049.0745140388772, 507.8434125269977),\n (219.89524838012954, 538.1673866090715),\n (877.6274298056157, 503.1781857451402)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.180227Z",
     "end_time": "2023-04-16T19:13:42.185376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "im = Image.open(img_path)\n",
    "draw = ImageDraw.Draw(im)\n",
    "for center in centers:\n",
    "    draw.point(center, fill=(255, 0, 0))\n",
    "im.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:42.185223Z",
     "end_time": "2023-04-16T19:13:43.119998Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(1920, 1080)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.size # width, height"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.121987Z",
     "end_time": "2023-04-16T19:13:43.125918Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a gaussian patch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def generate_patch(scale=12):\n",
    "    \"\"\"Creates a heatmap using Gaussian Distribution.\"\"\"\n",
    "\n",
    "    # constants.\n",
    "    sigma = 1\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x_mesh, y_mesh = torch.meshgrid(torch.arange(0, 6*sigma+1, 1), torch.arange(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "    # the center of the gaussian patch should be 1\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    # generate this 7x7 gaussian patch\n",
    "    xmesh = torch.square(torch.sub(x_mesh, center_x))\n",
    "    ymesh = torch.square(torch.sub(y_mesh, center_y))\n",
    "    denom = (sigma**2) * 2\n",
    "    gaussian_patch = torch.mul(torch.exp(torch.div(torch.neg(torch.add(xmesh, ymesh)), denom)), scale)\n",
    "\n",
    "    return gaussian_patch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.129260Z",
     "end_time": "2023-04-16T19:13:43.131675Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Displaying the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "w, h = im.size\n",
    "x, y = centers[0]\n",
    "patch = generate_patch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.132967Z",
     "end_time": "2023-04-16T19:13:43.137827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.2340980e-04, 1.5034392e-03, 6.7379470e-03, 1.1108996e-02,\n        6.7379470e-03, 1.5034392e-03, 1.2340980e-04],\n       [1.5034392e-03, 1.8315639e-02, 8.2084998e-02, 1.3533528e-01,\n        8.2084998e-02, 1.8315639e-02, 1.5034392e-03],\n       [6.7379470e-03, 8.2084998e-02, 3.6787945e-01, 6.0653067e-01,\n        3.6787945e-01, 8.2084998e-02, 6.7379470e-03],\n       [1.1108996e-02, 1.3533528e-01, 6.0653067e-01, 1.0000000e+00,\n        6.0653067e-01, 1.3533528e-01, 1.1108996e-02],\n       [6.7379470e-03, 8.2084998e-02, 3.6787945e-01, 6.0653067e-01,\n        3.6787945e-01, 8.2084998e-02, 6.7379470e-03],\n       [1.5034392e-03, 1.8315639e-02, 8.2084998e-02, 1.3533528e-01,\n        8.2084998e-02, 1.8315639e-02, 1.5034392e-03],\n       [1.2340980e-04, 1.5034392e-03, 6.7379470e-03, 1.1108996e-02,\n        6.7379470e-03, 1.5034392e-03, 1.2340980e-04]], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor.numpy(patch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.138567Z",
     "end_time": "2023-04-16T19:13:43.168672Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add an extra dimension in order to convert to PIL image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "patch = torch.unsqueeze(patch, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.142734Z",
     "end_time": "2023-04-16T19:13:43.169107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 7, 7])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.146352Z",
     "end_time": "2023-04-16T19:13:43.169285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "t = transforms.ToPILImage()\n",
    "patch_img = t(patch)\n",
    "patch_img.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.151300Z",
     "end_time": "2023-04-16T19:13:43.276951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000, 0.0000, 0.0039, 0.0078, 0.0039, 0.0000, 0.0000],\n         [0.0000, 0.0157, 0.0784, 0.1333, 0.0784, 0.0157, 0.0000],\n         [0.0039, 0.0784, 0.3647, 0.6039, 0.3647, 0.0784, 0.0039],\n         [0.0078, 0.1333, 0.6039, 1.0000, 0.6039, 0.1333, 0.0078],\n         [0.0039, 0.0784, 0.3647, 0.6039, 0.3647, 0.0784, 0.0039],\n         [0.0000, 0.0157, 0.0784, 0.1333, 0.0784, 0.0157, 0.0000],\n         [0.0000, 0.0000, 0.0039, 0.0078, 0.0039, 0.0000, 0.0000]]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_t = transforms.ToTensor()\n",
    "to_t(patch_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.280391Z",
     "end_time": "2023-04-16T19:13:43.288493Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Gaussian Patch is being created properly as seen by the output tensor after converting from img to tensor. Now we should try to figure out how to place the patch in the heatmap."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def heatmap(width, height, center_x, center_y, gau_patch):\n",
    "    \"\"\"Places a Gaussian Patch in the heatmap.\"\"\"\n",
    "\n",
    "    # constants.\n",
    "    heatmap = np.zeros((height, width))\n",
    "    sigma = 1\n",
    "    visibility = 2\n",
    "    gau_patch = torch.Tensor.numpy(gau_patch)\n",
    "\n",
    "    # this gaussian patch is 7x7, let's get four corners of it first\n",
    "    xmin = center_x - 3 * sigma\n",
    "    ymin = center_y - 3 * sigma\n",
    "    xmax = center_x + 3 * sigma\n",
    "    ymax = center_y + 3 * sigma\n",
    "\n",
    "    # if outside the image don't include the gaussian patch.\n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    # determine boundaries for patch if outside the image.\n",
    "    patch_xmin = max(0, -xmin)\n",
    "    patch_ymin = max(0, -ymin)\n",
    "    patch_xmax = min(xmax, width) - xmin\n",
    "    patch_ymax = min(ymax, height) - ymin\n",
    "\n",
    "    # we need to determine where to put this patch in the whole heatmap\n",
    "    heatmap_xmin = max(0, xmin)\n",
    "    heatmap_ymin = max(0, ymin)\n",
    "\n",
    "    for j in range(patch_ymin, patch_ymax):\n",
    "        for i in range(patch_xmin, patch_xmax):\n",
    "            heatmap[j+heatmap_ymin, i+heatmap_xmin] = gau_patch[j, i]\n",
    "\n",
    "    return torch.FloatTensor(heatmap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.287760Z",
     "end_time": "2023-04-16T19:13:43.294948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(1536.6555075593953, 598.8153347732183)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:43.300426Z",
     "end_time": "2023-04-16T19:13:43.316018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "heatmap_example = heatmap(int(w), int(h), int(x), int(y), patch)\n",
    "heatmap_img = t(heatmap_example)\n",
    "heatmap_img.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:53:56.821613Z",
     "end_time": "2023-04-16T17:53:56.976724Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Patch was applied to the image, but resizing the image eliminates the patch. So we should resize the image and keypoint coordinates, then apply patch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080)\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1108\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(img_path)\n",
    "print(im.size)\n",
    "im = im.resize((64, 64))\n",
    "im.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:44.253424Z",
     "end_time": "2023-04-16T19:13:44.411155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "rx, ry = 64/1920, 64/1080\n",
    "resized_centers = []\n",
    "for center in centers:\n",
    "    cx, cy = center\n",
    "    resized_centers.append((cx*rx, cy*ry))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:44.413480Z",
     "end_time": "2023-04-16T19:13:44.416298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw new center point in resized image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(im)\n",
    "for center in resized_centers:\n",
    "    draw.point(center, fill=(255, 0, 0))\n",
    "im.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:44.417751Z",
     "end_time": "2023-04-16T19:13:44.544960Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The centers are not deformed and in the correct locations. Now try to create a heatmap with all the possible center key points. We need to define a new heatmap function in order to see add multiple key points into the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def heatmap(width, height, keypoints, gau_patch):\n",
    "    \"\"\"Places a Gaussian Patch in the heatmap.\"\"\"\n",
    "\n",
    "    # constants.\n",
    "    heatmap = np.zeros((height, width))\n",
    "    sigma = 1\n",
    "    visibility = 2\n",
    "    gau_patch = torch.Tensor.numpy(gau_patch)\n",
    "\n",
    "    # this gaussian patch is 7x7, let's get four corners of it first\n",
    "    coordinates = []\n",
    "    for keypoint in keypoints:\n",
    "        center_x, center_y = keypoint\n",
    "        xmin = center_x - 3 * sigma\n",
    "        ymin = center_y - 3 * sigma\n",
    "        xmax = center_x + 3 * sigma\n",
    "        ymax = center_y + 3 * sigma\n",
    "        coordinates.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "    for coordinate in coordinates:\n",
    "        # unpack the coordinates.\n",
    "        xmin, ymin, xmax, ymax = coordinate\n",
    "\n",
    "        # if outside the image don't include the gaussian patch.\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "            pass\n",
    "\n",
    "        # determine boundaries for patch if outside the image.\n",
    "        patch_xmin = max(0, -xmin)\n",
    "        patch_ymin = max(0, -ymin)\n",
    "        patch_xmax = min(xmax, width) - xmin\n",
    "        patch_ymax = min(ymax, height) - ymin\n",
    "\n",
    "        # we need to determine where to put this patch in the whole heatmap\n",
    "        heatmap_xmin = int(max(0, xmin))\n",
    "        heatmap_ymin = int(max(0, ymin))\n",
    "\n",
    "        for j in range(int(patch_ymin), int(patch_ymax)):\n",
    "            for i in range(int(patch_xmin), int(patch_xmax)):\n",
    "                gau_pixel = gau_patch[j, i]\n",
    "                pixel = heatmap[j+heatmap_ymin, i+heatmap_xmin]\n",
    "                if pixel > 0:\n",
    "                    heatmap[j+heatmap_ymin, i+heatmap_xmin] = max(pixel, gau_pixel)\n",
    "                else:\n",
    "                    heatmap[j+heatmap_ymin, i+heatmap_xmin] = gau_pixel\n",
    "\n",
    "    return torch.FloatTensor(heatmap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:13:44.547894Z",
     "end_time": "2023-04-16T19:13:44.550783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[(51.221850251979845, 35.48535317174627),\n (34.96915046796257, 30.09442444604431),\n (7.329841612670985, 31.89140068794498),\n (29.25424766018719, 29.817966562674975)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1109\n"
     ]
    }
   ],
   "source": [
    "resized_centers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:20:14.335291Z",
     "end_time": "2023-04-16T19:20:14.339650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "patch = generate_patch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:20:58.731827Z",
     "end_time": "2023-04-16T19:20:58.737916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "heat_ex2 = heatmap(64, 64, resized_centers, patch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:21:21.443138Z",
     "end_time": "2023-04-16T19:21:21.446881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heat_ex2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T19:21:26.337423Z",
     "end_time": "2023-04-16T19:21:26.341439Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the images to HeatMaps and run the model in training and evaluation model. In other words create the dataset element in PyTorch and then generate training rounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
